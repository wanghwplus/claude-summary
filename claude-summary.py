#!/usr/bin/env python3
"""
claude-summary: Claude Code å¯¹è¯ç»éªŒè‡ªåŠ¨æ€»ç»“å·¥å…·

SessionStart hook è§¦å‘ â†’ æå–ä¸Šä¸€æ¬¡ transcript â†’ é˜Ÿåˆ—åŒ– â†’ claude -p æ€»ç»“ â†’ æŒ‰å¤©ä¿å­˜
å‘¨ä¸€è‡ªåŠ¨åˆå¹¶å‘¨æŠ¥ + æ¸…ç† + æœˆåº¦å½’æ¡£
"""

import json
import sys
import os
import fcntl
import glob
import hashlib
import time
import subprocess
import shutil
from datetime import datetime, date, timedelta
from pathlib import Path

# ============== é…ç½® ==============
BASE_DIR = os.environ.get("CLAUDE_SUMMARY_DIR", os.path.expanduser("~/.claude-summary"))
DAILY_DIR = os.path.join(BASE_DIR, "daily")
WEEKLY_DIR = os.path.join(BASE_DIR, "weekly")
MONTHLY_DIR = os.path.join(BASE_DIR, "monthly")
QUEUE_DIR = os.path.join(BASE_DIR, "queue")
SUMMARIZED_DIR = os.path.join(BASE_DIR, ".summarized")
LOCK_FILE = os.path.join(BASE_DIR, ".lock")
LOG_FILE = os.path.join(BASE_DIR, "claude-summary.log")

MIN_MESSAGES = int(os.environ.get("CLAUDE_SUMMARY_MIN_MESSAGES", "4"))
MODEL = os.environ.get("CLAUDE_SUMMARY_MODEL", "claude-sonnet-4-6")

SUMMARY_PROMPT = """ä½ æ˜¯ä¸€ä¸ªç»éªŒæ€»ç»“åŠ©æ‰‹ã€‚åˆ†æä»¥ä¸‹ Claude Code å¯¹è¯è®°å½•ï¼Œæå–å…³é”®ç»éªŒã€‚

è¦æ±‚ï¼š
1. åªæ€»ç»“æœ‰ä»·å€¼çš„æŠ€æœ¯ç»éªŒï¼Œå¿½ç•¥é—²èŠå’Œç®€å•é—®ç­”
2. å¦‚æœå¯¹è¯å¤ªç®€å•æ²¡æœ‰å€¼å¾—è®°å½•çš„ç»éªŒï¼Œåªå›å¤ä¸€ä¸ªè¯ SKIP
3. ç”¨ä¸­æ–‡è¾“å‡ºï¼Œç®€æ´æœ‰åŠ›

æ ¼å¼ï¼š
## ğŸ“‹ å¯¹è¯ä¸»é¢˜
[ä¸€å¥è¯æè¿°]

## ğŸ¯ è§£å†³çš„é—®é¢˜
[ç®€è¦åˆ—å‡º]

## ğŸ’¡ å…³é”®ç»éªŒ
[å¯å¤ç”¨çš„å…·ä½“ç»éªŒ]

## ğŸ”§ æœ‰ç”¨çš„ä»£ç /å‘½ä»¤
[å¦‚æœæœ‰å€¼å¾—è®°å½•çš„ç‰‡æ®µ]

## âš ï¸ è¸©å‘è®°å½•
[å¦‚æœæœ‰]

å¯¹è¯è®°å½•ï¼š
"""


def ensure_dirs():
    for d in [DAILY_DIR, WEEKLY_DIR, MONTHLY_DIR, QUEUE_DIR, SUMMARIZED_DIR]:
        os.makedirs(d, exist_ok=True)


def log(msg: str):
    """å†™æ—¥å¿—"""
    try:
        ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        with open(LOG_FILE, "a", encoding="utf-8") as f:
            f.write(f"[{ts}] {msg}\n")
    except Exception:
        pass


def transcript_hash(path: str) -> str:
    """transcript è·¯å¾„çš„å“ˆå¸Œï¼Œç”¨äºæ ‡è®°å·²æ€»ç»“"""
    return hashlib.md5(path.encode()).hexdigest()[:12]


def is_summarized(transcript_path: str) -> bool:
    """æ£€æŸ¥æ˜¯å¦å·²ç»æ€»ç»“è¿‡"""
    marker = os.path.join(SUMMARIZED_DIR, transcript_hash(transcript_path))
    return os.path.exists(marker)


def mark_summarized(transcript_path: str):
    """æ ‡è®°ä¸ºå·²æ€»ç»“"""
    marker = os.path.join(SUMMARIZED_DIR, transcript_hash(transcript_path))
    Path(marker).touch()


# ============== Transcript è§£æ ==============

def count_user_messages(transcript_path: str) -> int:
    count = 0
    try:
        with open(transcript_path, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                try:
                    entry = json.loads(line)
                    if entry.get("type") == "user":
                        count += 1
                except json.JSONDecodeError:
                    continue
    except Exception:
        pass
    return count


def extract_conversation(transcript_path: str, max_chars: int = 20000) -> str:
    """ä» JSONL transcript æå–å¯¹è¯æ–‡æœ¬ï¼Œå»æ‰å·¥å…·è°ƒç”¨ç»†èŠ‚"""
    if not os.path.exists(transcript_path):
        return ""

    messages = []
    total_len = 0

    try:
        with open(transcript_path, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                try:
                    entry = json.loads(line)
                except json.JSONDecodeError:
                    continue

                entry_type = entry.get("type", "")

                # summary è¡Œï¼ˆå¦‚æœæœ‰ï¼‰
                if entry_type == "summary":
                    summary = entry.get("summary", "")
                    if summary:
                        messages.insert(0, f"[å¯¹è¯æ‘˜è¦]: {summary}")
                        total_len += len(summary)
                    continue

                if entry_type not in ("user", "assistant"):
                    continue

                msg = entry.get("message", {})
                content = msg.get("content", [])
                role = "ç”¨æˆ·" if entry_type == "user" else "Claude"

                if isinstance(content, str):
                    text = content[:600] + "...[æˆªæ–­]" if len(content) > 600 else content
                    messages.append(f"{role}: {text}")
                    total_len += len(text)
                elif isinstance(content, list):
                    for block in content:
                        if not isinstance(block, dict):
                            continue
                        # åªæå–æ–‡æœ¬ï¼Œè·³è¿‡ tool_use / tool_result
                        if block.get("type") == "text":
                            text = block.get("text", "")
                            if not text:
                                continue
                            if len(text) > 600:
                                text = text[:600] + "...[æˆªæ–­]"
                            messages.append(f"{role}: {text}")
                            total_len += len(text)

                if total_len > max_chars:
                    messages.append("...[å¯¹è¯è¿‡é•¿å·²æˆªæ–­]")
                    break

    except Exception as e:
        log(f"è§£æ transcript å¤±è´¥: {e}")
        return ""

    return "\n\n".join(messages)


# ============== æŸ¥æ‰¾ä¸Šä¸€æ¬¡ Transcript ==============

def find_project_transcripts(cwd: str) -> list:
    """
    æ‰¾åˆ°å½“å‰é¡¹ç›®ç›®å½•å¯¹åº”çš„æ‰€æœ‰ transcript æ–‡ä»¶ã€‚
    Claude Code å°† transcript å­˜åœ¨ ~/.claude/projects/<encoded-path>/ ä¸‹ã€‚
    """
    claude_projects = os.path.expanduser("~/.claude/projects")
    if not os.path.exists(claude_projects):
        return []

    # Claude Code ç”¨è·¯å¾„ç¼–ç ä½œä¸ºé¡¹ç›®ç›®å½•åï¼ˆæŠŠ / æ›¿æ¢ä¸º -ï¼‰
    # å°è¯•åŒ¹é… cwd å¯¹åº”çš„é¡¹ç›®ç›®å½•
    all_transcripts = []

    for project_dir in os.listdir(claude_projects):
        project_path = os.path.join(claude_projects, project_dir)
        if not os.path.isdir(project_path):
            continue

        # æ£€æŸ¥ç›®å½•åæ˜¯å¦ä¸ cwd ç›¸å…³
        # Claude Code ç¼–ç è§„åˆ™ï¼š/Users/wang/project â†’ -Users-wang-project
        encoded_cwd = cwd.replace("/", "-")
        if encoded_cwd.startswith("-"):
            encoded_cwd_check = encoded_cwd
        else:
            encoded_cwd_check = "-" + encoded_cwd

        if project_dir == encoded_cwd_check or project_dir.startswith(encoded_cwd_check):
            jsonl_files = glob.glob(os.path.join(project_path, "*.jsonl"))
            all_transcripts.extend(jsonl_files)

    # å¦‚æœåŒ¹é…ä¸åˆ°ï¼Œé€€å›åˆ°æœç´¢æ‰€æœ‰é¡¹ç›®
    if not all_transcripts:
        all_transcripts = glob.glob(
            os.path.join(claude_projects, "**", "*.jsonl"), recursive=True
        )

    return all_transcripts


def find_previous_transcript(current_session_id: str, cwd: str) -> str:
    """æ‰¾åˆ°ä¸Šä¸€æ¬¡çš„ transcriptï¼ˆæ’é™¤å½“å‰ sessionï¼‰"""
    transcripts = find_project_transcripts(cwd)
    if not transcripts:
        return ""

    # æ’é™¤å½“å‰ session çš„ transcript
    candidates = [t for t in transcripts if current_session_id not in os.path.basename(t)]

    if not candidates:
        return ""

    # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œå–æœ€è¿‘çš„
    candidates.sort(key=lambda f: os.path.getmtime(f), reverse=True)
    return candidates[0]


# ============== é˜Ÿåˆ—ç®¡ç† ==============

def enqueue_task(transcript_path: str, cwd: str, session_id: str):
    """å†™å…¥é˜Ÿåˆ—"""
    ensure_dirs()
    task = {
        "transcript_path": transcript_path,
        "cwd": cwd,
        "session_id": session_id,
        "timestamp": time.time(),
        "created_at": datetime.now().isoformat()
    }
    filename = f"{int(time.time())}-{session_id[:8]}.json"
    filepath = os.path.join(QUEUE_DIR, filename)
    with open(filepath, "w", encoding="utf-8") as f:
        json.dump(task, f)
    log(f"å…¥é˜Ÿ: {filename} -> {transcript_path}")


def get_pending_tasks() -> list:
    """è·å–é˜Ÿåˆ—ä¸­å¾…å¤„ç†çš„ä»»åŠ¡ï¼ŒæŒ‰æ—¶é—´æ’åº"""
    tasks = []
    for filename in sorted(os.listdir(QUEUE_DIR)):
        if not filename.endswith(".json"):
            continue
        filepath = os.path.join(QUEUE_DIR, filename)
        try:
            with open(filepath, "r", encoding="utf-8") as f:
                task = json.load(f)
            task["_filepath"] = filepath
            tasks.append(task)
        except Exception:
            continue
    return tasks


def remove_task(task: dict):
    """åˆ é™¤å·²å¤„ç†çš„ä»»åŠ¡"""
    filepath = task.get("_filepath", "")
    if filepath and os.path.exists(filepath):
        os.remove(filepath)


# ============== æ€»ç»“ ==============

def summarize_with_claude(conversation: str) -> str:
    """ç”¨ claude -p ç”Ÿæˆæ€»ç»“"""
    prompt = SUMMARY_PROMPT + conversation
    try:
        result = subprocess.run(
            ["claude", "-p", "--model", MODEL, prompt],
            capture_output=True, text=True, timeout=120
        )
        if result.returncode == 0:
            return result.stdout.strip()
        else:
            log(f"claude -p å¤±è´¥: {result.stderr}")
            return ""
    except FileNotFoundError:
        log("claude å‘½ä»¤æœªæ‰¾åˆ°")
        return ""
    except subprocess.TimeoutExpired:
        log("claude -p è¶…æ—¶")
        return ""
    except Exception as e:
        log(f"claude -p å¼‚å¸¸: {e}")
        return ""


def save_daily(summary: str, session_id: str = ""):
    """ä¿å­˜åˆ°å½“å¤©çš„ daily æ–‡ä»¶"""
    today = date.today().isoformat()
    now = datetime.now().strftime("%H:%M")
    daily_file = os.path.join(DAILY_DIR, f"{today}.md")

    if not os.path.exists(daily_file):
        with open(daily_file, "w", encoding="utf-8") as f:
            f.write(f"# ğŸ“… {today} ç»éªŒæ€»ç»“\n")

    with open(daily_file, "a", encoding="utf-8") as f:
        f.write(f"\n---\n\n### â° {now}")
        if session_id:
            f.write(f"  `{session_id[:8]}`")
        f.write(f"\n\n{summary}\n")

    log(f"å·²ä¿å­˜ daily: {daily_file}")


def process_task(task: dict) -> bool:
    """å¤„ç†å•ä¸ªæ€»ç»“ä»»åŠ¡ï¼Œè¿”å›æ˜¯å¦æˆåŠŸ"""
    transcript_path = task.get("transcript_path", "")
    session_id = task.get("session_id", "")

    if not transcript_path or not os.path.exists(transcript_path):
        log(f"transcript ä¸å­˜åœ¨: {transcript_path}")
        return False

    # æ£€æŸ¥æ˜¯å¦å·²æ€»ç»“
    if is_summarized(transcript_path):
        log(f"å·²æ€»ç»“è¿‡ï¼Œè·³è¿‡: {transcript_path}")
        return True

    # æ£€æŸ¥æ¶ˆæ¯æ•°
    msg_count = count_user_messages(transcript_path)
    if msg_count < MIN_MESSAGES:
        log(f"æ¶ˆæ¯æ•° {msg_count} < {MIN_MESSAGES}ï¼Œè·³è¿‡")
        mark_summarized(transcript_path)
        return True

    # æå–å¯¹è¯
    conversation = extract_conversation(transcript_path)
    if not conversation:
        log("æœªæå–åˆ°å¯¹è¯å†…å®¹")
        mark_summarized(transcript_path)
        return True

    # è°ƒç”¨ claude -p æ€»ç»“
    log(f"å¼€å§‹æ€»ç»“: {transcript_path}")
    summary = summarize_with_claude(conversation)

    if not summary:
        log("æ€»ç»“å¤±è´¥")
        return False

    if summary.strip() == "SKIP":
        log("å¯¹è¯æ— éœ€æ€»ç»“")
        mark_summarized(transcript_path)
        return True

    # ä¿å­˜
    save_daily(summary, session_id)
    mark_summarized(transcript_path)
    return True


# ============== å‘¨ä¸€æ¸…ç†ä¸å½’æ¡£ ==============

def is_monday() -> bool:
    return date.today().weekday() == 0


def last_week_range():
    """è¿”å›ä¸Šå‘¨ä¸€å’Œä¸Šå‘¨æ—¥çš„æ—¥æœŸ"""
    today = date.today()
    last_monday = today - timedelta(days=today.weekday() + 7)
    last_sunday = last_monday + timedelta(days=6)
    return last_monday, last_sunday


def generate_weekly():
    """åˆå¹¶ä¸Šå‘¨çš„ daily ä¸ºå‘¨æŠ¥"""
    last_mon, last_sun = last_week_range()
    weekly_file = os.path.join(WEEKLY_DIR, f"week-{last_mon.isoformat()}.md")

    # å·²å­˜åœ¨åˆ™è·³è¿‡
    if os.path.exists(weekly_file):
        return

    daily_files = []
    for f in sorted(os.listdir(DAILY_DIR)):
        if not f.endswith(".md"):
            continue
        file_date_str = f.replace(".md", "")
        try:
            file_date = date.fromisoformat(file_date_str)
        except ValueError:
            continue
        if last_mon <= file_date <= last_sun:
            daily_files.append(os.path.join(DAILY_DIR, f))

    if not daily_files:
        log("ä¸Šå‘¨æ—  daily è®°å½•ï¼Œè·³è¿‡å‘¨æŠ¥")
        return

    with open(weekly_file, "w", encoding="utf-8") as wf:
        wf.write(f"# ğŸ“Š å‘¨æŠ¥: {last_mon.isoformat()} ~ {last_sun.isoformat()}\n")
        for df in daily_files:
            wf.write("\n")
            with open(df, "r", encoding="utf-8") as f:
                wf.write(f.read())

    log(f"å‘¨æŠ¥å·²ç”Ÿæˆ: {weekly_file}")

    # åˆ é™¤ä¸Šå‘¨çš„ daily æ–‡ä»¶
    for df in daily_files:
        os.remove(df)
        log(f"å·²æ¸…ç† daily: {df}")


def cleanup_summarized():
    """æ¸…ç†ä¸Šå‘¨çš„å·²æ€»ç»“æ ‡è®°"""
    one_week_ago = time.time() - 7 * 86400
    for f in os.listdir(SUMMARIZED_DIR):
        filepath = os.path.join(SUMMARIZED_DIR, f)
        try:
            if os.path.getmtime(filepath) < one_week_ago:
                os.remove(filepath)
        except Exception:
            pass


def cleanup_queue():
    """æ¸…ç†è¶…è¿‡ä¸€å‘¨çš„é˜Ÿåˆ—æ®‹ç•™"""
    one_week_ago = time.time() - 7 * 86400
    for f in os.listdir(QUEUE_DIR):
        filepath = os.path.join(QUEUE_DIR, f)
        try:
            if os.path.getmtime(filepath) < one_week_ago:
                os.remove(filepath)
        except Exception:
            pass


def archive_monthly():
    """å¦‚æœä¸Šä¸ªæœˆç»“æŸäº†ï¼ŒæŠŠä¸Šä¸ªæœˆçš„ weekly ç§»åˆ° monthly ç›®å½•"""
    today = date.today()
    if today.day > 7:
        # åªåœ¨æœˆåˆå‰7å¤©æ‰§è¡Œ
        return

    last_month = today.replace(day=1) - timedelta(days=1)
    last_month_str = last_month.strftime("%Y-%m")
    month_dir = os.path.join(MONTHLY_DIR, last_month_str)

    moved = False
    for f in os.listdir(WEEKLY_DIR):
        if not f.endswith(".md"):
            continue
        # week-2025-01-06.md â†’ æå–æ—¥æœŸ
        try:
            week_date_str = f.replace("week-", "").replace(".md", "")
            week_date = date.fromisoformat(week_date_str)
        except ValueError:
            continue

        if week_date.strftime("%Y-%m") == last_month_str:
            os.makedirs(month_dir, exist_ok=True)
            src = os.path.join(WEEKLY_DIR, f)
            dst = os.path.join(month_dir, f)
            shutil.move(src, dst)
            log(f"æœˆåº¦å½’æ¡£: {f} -> {month_dir}/")
            moved = True

    if moved:
        log(f"æœˆåº¦å½’æ¡£å®Œæˆ: {last_month_str}")


def monday_maintenance():
    """å‘¨ä¸€ç»´æŠ¤ä»»åŠ¡"""
    if not is_monday():
        return

    # ç”¨æ ‡è®°æ–‡ä»¶é¿å…åŒä¸€å¤©é‡å¤æ‰§è¡Œ
    marker = os.path.join(BASE_DIR, f".maintenance-{date.today().isoformat()}")
    if os.path.exists(marker):
        return

    log("æ‰§è¡Œå‘¨ä¸€ç»´æŠ¤...")
    generate_weekly()
    cleanup_summarized()
    cleanup_queue()
    archive_monthly()
    Path(marker).touch()

    # æ¸…ç†æ—§çš„ maintenance æ ‡è®°
    for f in glob.glob(os.path.join(BASE_DIR, ".maintenance-*")):
        try:
            fname = os.path.basename(f)
            d = date.fromisoformat(fname.replace(".maintenance-", ""))
            if d < date.today() - timedelta(days=7):
                os.remove(f)
        except Exception:
            pass

    log("å‘¨ä¸€ç»´æŠ¤å®Œæˆ")


# ============== ä¸»æµç¨‹ï¼šHook å…¥å£ ==============

def hook_main():
    """SessionStart hook å…¥å£"""
    ensure_dirs()

    # è¯»å– hook JSON
    hook_data = {}
    try:
        if not sys.stdin.isatty():
            hook_data = json.load(sys.stdin)
    except Exception:
        pass

    session_id = hook_data.get("session_id", f"manual-{int(time.time())}")
    cwd = hook_data.get("cwd", os.getcwd())

    # æ‰¾ä¸Šä¸€æ¬¡çš„ transcript
    transcript_path = find_previous_transcript(session_id, cwd)
    if not transcript_path:
        log("æœªæ‰¾åˆ°ä¸Šä¸€æ¬¡çš„ transcript")
        return

    if is_summarized(transcript_path):
        log(f"ä¸Šä¸€æ¬¡å¯¹è¯å·²æ€»ç»“è¿‡: {transcript_path}")
        # ä»ç„¶æ£€æŸ¥å‘¨ä¸€ç»´æŠ¤
        monday_maintenance()
        return

    # å…¥é˜Ÿ
    enqueue_task(transcript_path, cwd, session_id)

    # å°è¯•è·å–é”å¹¶å¤„ç†é˜Ÿåˆ—
    process_queue()


def process_queue():
    """å°è¯•è·å–é”ï¼Œå¤„ç†é˜Ÿåˆ—ä¸­æ‰€æœ‰ä»»åŠ¡"""
    lock_fd = None
    try:
        lock_fd = open(LOCK_FILE, "w")
        fcntl.flock(lock_fd, fcntl.LOCK_EX | fcntl.LOCK_NB)
    except (IOError, OSError):
        # æ²¡æ‹¿åˆ°é”ï¼Œæœ‰å…¶ä»–è¿›ç¨‹åœ¨å¤„ç†
        log("é”è¢«å ç”¨ï¼Œé€€å‡º")
        if lock_fd:
            lock_fd.close()
        return

    try:
        # å¾ªç¯å¤„ç†ç›´åˆ°é˜Ÿåˆ—ç©º
        while True:
            tasks = get_pending_tasks()
            if not tasks:
                break

            task = tasks[0]
            success = process_task(task)
            remove_task(task)

            if not success:
                log(f"ä»»åŠ¡å¤„ç†å¤±è´¥: {task.get('transcript_path', '?')}")

        # é˜Ÿåˆ—å¤„ç†å®Œï¼Œæ‰§è¡Œå‘¨ä¸€ç»´æŠ¤
        monday_maintenance()

    finally:
        fcntl.flock(lock_fd, fcntl.LOCK_UN)
        lock_fd.close()


# ============== CLI å…¥å£ ==============

def cli_show(target: str = "today"):
    """æŸ¥çœ‹è®°å½•"""
    ensure_dirs()
    if target == "today":
        f = os.path.join(DAILY_DIR, f"{date.today().isoformat()}.md")
        if os.path.exists(f):
            print(open(f, encoding="utf-8").read())
        else:
            print("ğŸ“­ ä»Šå¤©æ²¡æœ‰è®°å½•")
    elif target == "week":
        today = date.today()
        monday = today - timedelta(days=today.weekday())
        for f in sorted(os.listdir(DAILY_DIR)):
            if not f.endswith(".md"):
                continue
            try:
                fd = date.fromisoformat(f.replace(".md", ""))
                if fd >= monday:
                    print(f"\n{'â”' * 40} {fd} {'â”' * 40}")
                    print(open(os.path.join(DAILY_DIR, f), encoding="utf-8").read())
            except ValueError:
                continue
    elif target == "all":
        # daily
        for f in sorted(os.listdir(DAILY_DIR)):
            if f.endswith(".md"):
                print(f"\n{'â”' * 40} {f} {'â”' * 40}")
                print(open(os.path.join(DAILY_DIR, f), encoding="utf-8").read())
        # weekly
        for f in sorted(os.listdir(WEEKLY_DIR)):
            if f.endswith(".md"):
                print(f"\n{'â”' * 40} {f} {'â”' * 40}")
                print(open(os.path.join(WEEKLY_DIR, f), encoding="utf-8").read())
        # monthly
        for month_dir in sorted(os.listdir(MONTHLY_DIR)):
            month_path = os.path.join(MONTHLY_DIR, month_dir)
            if os.path.isdir(month_path):
                for f in sorted(os.listdir(month_path)):
                    if f.endswith(".md"):
                        print(f"\n{'â”' * 40} {month_dir}/{f} {'â”' * 40}")
                        print(open(os.path.join(month_path, f), encoding="utf-8").read())
    else:
        # å°è¯•ä½œä¸ºæ—¥æœŸ
        f = os.path.join(DAILY_DIR, f"{target}.md")
        if os.path.exists(f):
            print(open(f, encoding="utf-8").read())
        else:
            print(f"âŒ æ‰¾ä¸åˆ° {target} çš„è®°å½•")


def cli_list():
    """åˆ—è¡¨æ¦‚è§ˆ"""
    ensure_dirs()
    print("ğŸ“ è®°å½•åˆ—è¡¨:\n")

    daily_files = sorted(glob.glob(os.path.join(DAILY_DIR, "*.md")))
    if daily_files:
        print("ğŸ“… æ¯æ—¥:")
        for f in daily_files:
            d = os.path.basename(f).replace(".md", "")
            try:
                with open(f, encoding="utf-8") as fh:
                    n = fh.read().count("### â°")
            except Exception:
                n = 0
            print(f"  {d}  ({n} æ¡)")

    weekly_files = sorted(glob.glob(os.path.join(WEEKLY_DIR, "*.md")))
    if weekly_files:
        print("\nğŸ“Š æœ¬æœˆå‘¨æŠ¥:")
        for f in weekly_files:
            print(f"  {os.path.basename(f).replace('.md', '')}")

    monthly_dirs = sorted(glob.glob(os.path.join(MONTHLY_DIR, "*")))
    if monthly_dirs:
        print("\nğŸ“¦ æœˆåº¦å½’æ¡£:")
        for md in monthly_dirs:
            if os.path.isdir(md):
                count = len(glob.glob(os.path.join(md, "*.md")))
                print(f"  {os.path.basename(md)}  ({count} ä¸ªå‘¨æŠ¥)")


def cli_search(keyword: str):
    """æœç´¢"""
    ensure_dirs()
    found = False
    for search_dir in [DAILY_DIR, WEEKLY_DIR]:
        for f in sorted(glob.glob(os.path.join(search_dir, "*.md"))):
            try:
                content = open(f, encoding="utf-8").read()
                lines = content.split("\n")
                for i, line in enumerate(lines, 1):
                    if keyword.lower() in line.lower():
                        fname = os.path.basename(f)
                        print(f"  {fname}:{i}: {line.strip()}")
                        found = True
            except Exception:
                continue

    # æœç´¢æœˆåº¦å½’æ¡£
    for month_dir in sorted(glob.glob(os.path.join(MONTHLY_DIR, "*"))):
        if os.path.isdir(month_dir):
            for f in sorted(glob.glob(os.path.join(month_dir, "*.md"))):
                try:
                    content = open(f, encoding="utf-8").read()
                    lines = content.split("\n")
                    for i, line in enumerate(lines, 1):
                        if keyword.lower() in line.lower():
                            rel = os.path.relpath(f, BASE_DIR)
                            print(f"  {rel}:{i}: {line.strip()}")
                            found = True
                except Exception:
                    continue

    if not found:
        print("æœªæ‰¾åˆ°åŒ¹é…ç»“æœ")


def cli_status():
    """æ˜¾ç¤ºçŠ¶æ€"""
    ensure_dirs()
    queue_count = len([f for f in os.listdir(QUEUE_DIR) if f.endswith(".json")])
    summarized_count = len(os.listdir(SUMMARIZED_DIR))
    lock_active = False
    try:
        fd = open(LOCK_FILE, "w")
        fcntl.flock(fd, fcntl.LOCK_EX | fcntl.LOCK_NB)
        fcntl.flock(fd, fcntl.LOCK_UN)
        fd.close()
    except (IOError, OSError):
        lock_active = True

    print(f"ğŸ“Š claude-summary çŠ¶æ€")
    print(f"  å­˜å‚¨ç›®å½•:     {BASE_DIR}")
    print(f"  é˜Ÿåˆ—ä¸­:       {queue_count} ä¸ªä»»åŠ¡")
    print(f"  å·²æ€»ç»“:       {summarized_count} ä¸ªå¯¹è¯")
    print(f"  æ€»ç»“æ¨¡å‹:     {MODEL}")
    print(f"  æ­£åœ¨å¤„ç†:     {'æ˜¯' if lock_active else 'å¦'}")
    print(f"  ä»Šå¤©æ˜¯å‘¨ä¸€:   {'æ˜¯' if is_monday() else 'å¦'}")

    if os.path.exists(LOG_FILE):
        print(f"\nğŸ“ æœ€è¿‘æ—¥å¿—:")
        try:
            with open(LOG_FILE, encoding="utf-8") as f:
                lines = f.readlines()
                for line in lines[-10:]:
                    print(f"  {line.rstrip()}")
        except Exception:
            pass


def usage():
    print("""ğŸ“˜ claude-summary - Claude Code å¯¹è¯ç»éªŒè‡ªåŠ¨æ€»ç»“å·¥å…·

ç”¨æ³•:
  claude-summary hook              SessionStart hook å…¥å£ï¼ˆè‡ªåŠ¨è°ƒç”¨ï¼‰
  claude-summary show [today|week|all|æ—¥æœŸ]  æŸ¥çœ‹è®°å½•
  claude-summary list              åˆ—è¡¨æ¦‚è§ˆ
  claude-summary search <å…³é”®è¯>    æœç´¢
  claude-summary status            æŸ¥çœ‹çŠ¶æ€
  claude-summary maintenance       æ‰‹åŠ¨æ‰§è¡Œå‘¨ä¸€ç»´æŠ¤""")


def main():
    args = sys.argv[1:]
    cmd = args[0] if args else "help"

    if cmd == "hook":
        hook_main()
    elif cmd == "show":
        cli_show(args[1] if len(args) > 1 else "today")
    elif cmd == "list":
        cli_list()
    elif cmd == "search":
        if len(args) < 2:
            print("âŒ è¯·æä¾›å…³é”®è¯")
            sys.exit(1)
        cli_search(args[1])
    elif cmd == "status":
        cli_status()
    elif cmd == "maintenance":
        monday_maintenance()
    elif cmd in ("help", "--help", "-h"):
        usage()
    else:
        print(f"âŒ æœªçŸ¥å‘½ä»¤: {cmd}")
        usage()
        sys.exit(1)


if __name__ == "__main__":
    main()
